import streamlit as st
from google.genai import Client
import plotly.graph_objects as go
import re

# ==========================================
# 1. é é¢é…ç½®èˆ‡å°ˆæ¥­ UI æ¨£å¼
# ==========================================
st.set_page_config(page_title="DSE AI è¶…ç´šå°å¸« Pro", layout="wide")

st.markdown("""
    <style>
    .stApp { background-color: #f8f9fa; }
    h1 { color: #1e3a8a !important; font-weight: 800; border-bottom: 3px solid #fbbf24; padding-bottom: 10px; }
    .stButton>button { 
        background-color: #1e3a8a; color: white; border-radius: 8px; 
        font-weight: bold; width: 100%; transition: 0.3s;
    }
    .stButton>button:hover { background-color: #fbbf24; color: #1e3a8a; }
    .stChatMessage { border-radius: 15px; margin-bottom: 10px; }
    .report-card { 
        background-color: white; padding: 20px; border-radius: 12px; 
        box-shadow: 0 2px 4px rgba(0,0,0,0.05); border-left: 5px solid #fbbf24;
    }
    </style>
    """, unsafe_allow_html=True)

# ==========================================
# 2. åˆå§‹åŒ– API å®¢æˆ·ç«¯
# ==========================================
# è«‹ç¢ºä¿åœ¨ Streamlit çš„ Secrets ä¸­è¨­å®šäº† GEMINI_API_KEY
api_key_val = st.secrets.get("GEMINI_API_KEY", "")

@st.cache_resource
def get_client(key):
    return Client(api_key=key) if key else None

client = get_client(api_key_val)

# ==========================================
# 3. åˆå§‹åŒ–ç‹€æ…‹è®Šé‡ (é˜²æ­¢åˆ·æ–°ä¸Ÿå¤±æ•¸æ“š)
# ==========================================
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []  # å­˜å„²å°è©±ç´€éŒ„
if "scores" not in st.session_state:
    st.session_state.scores = {"Content": 0, "Organization": 0, "Language": 0}
if "last_report" not in st.session_state:
    st.session_state.last_report = ""
if "essay_text" not in st.session_state:
    st.session_state.essay_text = ""

# ==========================================
# 4. å´é‚Šæ¬„ï¼šå¯†ç¢¼é©—è­‰èˆ‡å·¥å…·ç®±
# ==========================================
with st.sidebar:
    st.title("ğŸ” å°å¸«æ¥å…¥é¢æ¿")
    # ä½ çš„ç™»å…¥å¯†ç¢¼å°±åœ¨é€™è£¡è¨­å®š
    access_code = st.text_input("è«‹è¼¸å…¥é‚€è«‹ç¢¼è§£é–", type="password")
    
    if access_code != "DSE2026":
        st.warning("ğŸ”’ è«‹è¼¸å…¥æ­£ç¢ºé‚€è«‹ç¢¼ä»¥ä½¿ç”¨ AI åŠŸèƒ½ã€‚")
        st.info("ğŸ’¡ æç¤ºï¼šé‚€è«‹ç¢¼ç‚º DSE2026")
        st.stop()
    
    st.success("âœ… é©—è­‰æˆåŠŸï¼")
    st.divider()
    st.title("ğŸ“š DSE æåˆ†å·¥å…·")
    with st.expander("5** å¿…èƒŒé€£è©"):
        st.markdown("- **Paradoxically** (çŸ›ç›¾åœ°)\n- **Notwithstanding** (å„˜ç®¡)\n- **In tandem with** (èˆ‡...åŒæ™‚)")
    with st.expander("è©å½™å‡ç´šè¡¨"):
        st.table({"æ™®é€š": ["Think", "Help", "Big"], "5**ç´šåˆ¥": ["Advocate", "Facilitate", "Substantial"]})

# ==========================================
# 5. ä¸»ç•Œé¢ä½ˆå±€
# ==========================================
st.title("ğŸ¤– DSE AI è¶…ç´šå°å¸« Pro")
st.caption("åŸºæ–¼è€ƒå®˜é‚è¼¯çš„ 1-on-1 æ·±åº¦æ‰¹æ”¹èˆ‡äº’å‹•å¹³å°")

tab_marker, tab_lab = st.tabs(["ğŸ“ ä½œæ–‡æ·±åº¦æ‰¹æ”¹", "âœ¨ é‡‘å¥å¯¦é©—å®¤"])

# --- Tab 1: ä½œæ–‡æ‰¹æ”¹ ---
with tab_marker:
    col1, col2 = st.columns([1, 1], gap="large")

    with col1:
        st.markdown("### ğŸ“¥ ç¬¬ä¸€æ­¥ï¼šæäº¤ä½œæ–‡")
        task_type = st.selectbox("é¸æ“‡é¡Œå‹", ["Part A", "Part B", "Argumentative", "Letter to Editor"])
        target_lv = st.select_slider("ç›®æ¨™ç­‰ç´š", options=["3", "4", "5", "5*", "5**"])
        user_text = st.text_area("åœ¨æ­¤ç²˜è²¼ä½ çš„ä½œæ–‡...", height=300, value=st.session_state.essay_text)
        
        if st.button("ğŸš€ ç”Ÿæˆè€ƒå®˜ç´šæ‰¹æ”¹å ±å‘Š"):
            if user_text:
                st.session_state.essay_text = user_text # ä¿å­˜æ–‡ç« å…§å®¹
                with st.spinner("é–±å·å®˜æ­£åœ¨ç²¾ç¢ºæ‰“åˆ†ä¸¦æ’°å¯«å ±å‘Š..."):
                    prompt = f"""
                    ä½ æ˜¯ä¸€ä½ç²¾é€šé¦™æ¸¯ DSE è©•åˆ†æ¨™æº–çš„è‹±æ–‡ç§‘é–±å·å®˜ã€‚
                    è«‹å°é€™ç¯‡ {task_type} ä½œæ–‡çµ¦äºˆ Level {target_lv} ç›®æ¨™çš„åŒå­¸å¯«ä¸€ä»½è©³ç›¡å ±å‘Šã€‚
                    è¦æ±‚ï¼š
                    1. æŒ‡å‡º Content, Organization, Language ä¸‰æ–¹é¢çš„å…·é«”åŠ åˆ†é»èˆ‡æ‰£åˆ†é»ã€‚
                    2. æä¾›ä¸€æ®µ Level 5** æ°´å¹³çš„ç¯„æ–‡æ”¹å¯«ã€‚
                    3. æœ€å¾Œä¸€è¡Œå¿…é ˆåš´æ ¼æŒ‰ç…§æ­¤æ ¼å¼è¼¸å‡ºåˆ†æ•¸ï¼šSCORES: C:æ•¸å­—, O:æ•¸å­—, L:æ•¸å­— (æ¯é …æ»¿åˆ† 7 åˆ†)
                    è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚
                    """
                    response = client.models.generate_content(
                        model="gemini-2.0-flash", 
                        contents=[prompt, user_text]
                    )
                    full_text = response.text
                    
                    # æå–åˆ†æ•¸ä¸¦æ›´æ–°é›·é”åœ–
                    score_match = re.search(r"SCORES:\s*C:(\d),\s*O:(\d),\s*L:(\d)", full_text)
                    if score_match:
                        st.session_state.scores = {
                            "Content": int(score_match.group(1)),
                            "Organization": int(score_match.group(2)),
                            "Language": int(score_match.group(3))
                        }
                    
                    st.session_state.last_report = full_text.split("SCORES:")[0]
                    # é‡ç½®å°è©±æ¡†ä¸¦è®“ AI å°å¸«ä¸»å‹•å¼•å°
                    st.session_state.chat_history = [
                        {"role": "assistant", "content": "æˆ‘æ˜¯ä½ çš„å°ˆå±¬å°å¸«ã€‚å ±å‘Šå·²ç”Ÿæˆï¼Œä½ å¯ä»¥æŸ¥çœ‹å·¦å´çš„é›·é”åœ–äº†è§£å¼±é …ï¼Œä¸æ˜ç™½çš„åœ°æ–¹åœ¨å³å´éš¨æ™‚å•æˆ‘ï¼"}
                    ]
            else:
                st.warning("è«‹å…ˆè¼¸å…¥ä½œæ–‡å…§å®¹ã€‚")

        # é¡¯ç¤ºå ±å‘Šçµæœ
        if st.session_state.last_report:
            st.markdown("---")
            st.markdown("### ğŸ“Š è©•åˆ†åˆ†æ")
            categories = list(st.session_state.scores.keys())
            values = list(st.session_state.scores.values())
            fig = go.Figure(data=go.Scatterpolar(r=values + [values[0]], theta=categories + [categories[0]], fill='toself', line_color='#1e3a8a'))
            fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 7])), showlegend=False, height=350)
            st.plotly_chart(fig, use_container_width=True)
            
            st.markdown("### ğŸ“‹ æ‰¹æ”¹å ±å‘Šå…§å®¹")
            st.markdown(f'<div class="report-card">{st.session_state.last_report}</div>', unsafe_allow_html=True)

    with col2:
        st.markdown("### ğŸ’¬ ç¬¬äºŒæ­¥ï¼šå°å¸« 1-on-1 è¿½å•")
        if not st.session_state.last_report:
            st.info("å®Œæˆå·¦å´æ‰¹æ”¹å¾Œï¼Œå°å¸«å°‡åœ¨æ­¤ç‚ºä½ è§£ç­”ç–‘å•ã€‚")
        else:
            # æ¸²æŸ“å°è©±ç´€éŒ„
            for msg in st.session_state.chat_history:
                with st.chat_message(msg["role"]):
                    st.write(msg["content"])
            
            # ä½¿ç”¨ chat_input çµ„ä»¶
            if prompt_input := st.chat_input("è€å¸«ï¼Œç‚ºä»€éº¼é€™è£¡å»ºè­°é€™æ¨£æ”¹ï¼Ÿ"):
                st.session_state.chat_history.append({"role": "user", "content": prompt_input})
                with st.chat_message("user"):
                    st.write(prompt_input)
                
                with st.chat_message("assistant"):
                    with st.spinner("å°å¸«æ€è€ƒä¸­..."):
                        # å°‡ä¸Šä¸‹æ–‡ï¼ˆåŸæ–‡+å ±å‘Š+æå•ï¼‰å®Œæ•´ç™¼é€
                        context = f"""
                        å­¸ç”ŸåŸæ–‡: {st.session_state.essay_text}
                        ä½ çš„æ‰¹æ”¹å ±å‘Š: {st.session_state.last_report}
                        å­¸ç”Ÿç¾åœ¨å•ä½ : {prompt_input}
                        è«‹ä½œç‚ºå°ˆæ¥­å°å¸«çµ¦äºˆå›ç­”ã€‚
                        """
                        response = client.models.generate_content(model="gemini-2.0-flash", contents=context)
                        st.write(response.text)
                        st.session_state.chat_history.append({"role": "assistant", "content": response.text})

# --- Tab 2: é‡‘å¥å¯¦é©—å®¤ ---
with tab_lab:
    st.markdown("### âœ¨ Level 5** é‡‘å¥å‡ç´šå¯¦é©—å®¤")
    st.info("è¼¸å…¥ä¸€å€‹å¹³å‡¡çš„å¥å­ï¼Œè®“ AI å°‡å…¶è½‰åŒ–ç‚º DSE é«˜åˆ†å¥å¼ã€‚")
    s_input = st.text_input("è¼¸å…¥ä½ æƒ³å‡ç´šçš„å¥å­ï¼š", placeholder="Education is very important for our future.")
    if st.button("âœ¨ ç¬é–“å‡ç´š"):
        if s_input:
            with st.spinner("æ­£åœ¨ç…‰é‡‘..."):
                lab_prompt = f"å°‡æ­¤å¥å­å‡ç´šç‚ºé¦™æ¸¯ DSE Level 5** æ°´å¹³ï¼Œä¸¦ç”¨ç¹é«”ä¸­æ–‡è§£é‡‹ä½¿ç”¨äº†ä»€éº¼é«˜ç´šå¥å¼æˆ–è©å½™ï¼š{s_input}"
                res = client.models.generate_content(model="gemini-2.0-flash", contents=lab_prompt)
                st.success(res.text)
        else:
            st.warning("è«‹å…ˆè¼¸å…¥å¥å­ã€‚")
