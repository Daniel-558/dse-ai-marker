import streamlit as st
from google.genai import Client

# 1. é…ç½®
st.set_page_config(page_title="DSE è¶…çº§å¯¼å¸ˆ AI", layout="wide")
api_key_val = st.secrets.get("GEMINI_API_KEY", "")

@st.cache_resource
def get_client(key):
    return Client(api_key=key) if key else None

client = get_client(api_key_val)

# åˆå§‹åŒ–å¯¹è¯å†å²
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "last_report" not in st.session_state:
    st.session_state.last_report = ""

st.title("ğŸ¤– DSE AI è¶…çº§å¯¼å¸ˆ")
st.caption("24å°æ—¶åœ¨çº¿ï¼šæ‰¹æ”¹ã€è®²è§£ã€è¿½é—®ï¼Œä¸€ç«™å¼æå®š")

col1, col2 = st.columns([1, 1])

with col1:
    st.markdown("### âœï¸ ç¬¬ä¸€æ­¥ï¼šæäº¤ä½œæ–‡")
    task_type = st.selectbox("é€‰æ‹©é¢˜å‹", ["Part A", "Part B", "Argumentative", "Letter to Editor"])
    target_lv = st.select_slider("ç›®æ ‡ç­‰çº§", options=["3", "4", "5", "5*", "5**"])
    user_text = st.text_area("ç²˜è´´ä½ çš„ä½œæ–‡å†…å®¹...", height=250)
    
    if st.button("ğŸš€ æ·±åº¦æ‰¹æ”¹æŠ¥å‘Š", use_container_width=True):
        if user_text:
            with st.spinner("é˜…å·å®˜æ­£åœ¨æ·±åº¦åˆ†æ..."):
                prompt = f"ä½ æ˜¯ä¸€ä½ç²¾é€šDSEè¯„åˆ†æ ‡å‡†çš„è€ƒå®˜ï¼Œè¯·é’ˆå¯¹è¿™ç¯‡{task_type}ä½œæ–‡ç»™Level {target_lv}ç›®æ ‡çš„åŒå­¦å†™ä¸€ä»½è¯¦ç»†æ‰¹æ”¹æŠ¥å‘Šã€‚å¿…é¡»åŒ…å«è¯„åˆ†ã€è¯­æ³•æ”¹è¿›å»ºè®®ã€5**èŒƒæ–‡æ”¹å†™å’ŒKillerè¯æ±‡ã€‚è¯·ç”¨ç¹ä½“ä¸­æ–‡ã€‚"
                response = client.models.generate_content(model="gemini-3-flash-preview", contents=[prompt, user_text])
                st.session_state.last_report = response.text
                # å­˜å…¥å¯¹è¯èƒŒæ™¯
                st.session_state.chat_history = [("AI", "è¿™æ˜¯ä½ çš„æ‰¹æ”¹æŠ¥å‘Šã€‚å¦‚æœæœ‰ä»»ä½•ä¸æ˜ç™½çš„åœ°æ–¹ï¼Œæ¯”å¦‚æŸä¸ªè¯­æ³•ç‚¹æˆ–è¯æ±‡ç”¨æ³•ï¼Œå¯ä»¥ç›´æ¥åœ¨ä¸‹æ–¹é—®æˆ‘ï¼")]
        else:
            st.warning("è¯·è¾“å…¥å†…å®¹")

    if st.session_state.last_report:
        st.markdown("---")
        st.markdown("### ğŸ’¡ æ‰¹æ”¹è¯¦æƒ…")
        st.markdown(st.session_state.last_report)

with col2:
    st.markdown("### ğŸ’¬ ç¬¬äºŒ stepï¼šä¸å¯¼å¸ˆäº’åŠ¨")
    if not st.session_state.last_report:
        st.info("å®Œæˆå·¦ä¾§æ‰¹æ”¹åï¼Œå³å¯å¼€å¯ 1-on-1 è¿½é—®æ¨¡å¼ã€‚")
    else:
        # æ˜¾ç¤ºå¯¹è¯å†å²
        for role, text in st.session_state.chat_history:
            with st.chat_message(role):
                st.write(text)
        
        # è¿½é—®è¾“å…¥æ¡†
        if prompt_input := st.chat_input("é—®é—®å¯¼å¸ˆï¼šä¸ºä»€ä¹ˆè¿™é‡Œè¦è¿™æ ·æ”¹ï¼Ÿ"):
            st.session_state.chat_history.append(("User", prompt_input))
            with st.chat_message("User"):
                st.write(prompt_input)
            
            with st.chat_message("AI"):
                # å°†ä½œæ–‡å†…å®¹ã€æ‰¹æ”¹æŠ¥å‘Šå’Œå¯¹è¯å†å²ä½œä¸ºä¸Šä¸‹æ–‡å‘ç»™ AI
                context = f"å­¦ç”Ÿä½œæ–‡: {user_text}\n\nä½ çš„æ‰¹æ”¹æŠ¥å‘Š: {st.session_state.last_report}\n\nå­¦ç”Ÿç°åœ¨é—®: {prompt_input}"
                response = client.models.generate_content(model="gemini-3-flash-preview", contents=context)
                st.write(response.text)
                st.session_state.chat_history.append(("AI", response.text))
