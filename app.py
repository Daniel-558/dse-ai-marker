import streamlit as st
from google.genai import Client
import plotly.graph_objects as go
import re

# 1. é…ç½®
st.set_page_config(page_title="DSE è¶…çº§å¯¼å¸ˆ AI", layout="wide")
api_key_val = st.secrets.get("GEMINI_API_KEY", "")

@st.cache_resource
def get_client(key):
    return Client(api_key=key) if key else None

client = get_client(api_key_val)

# åˆå§‹åŒ–çŠ¶æ€
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "scores" not in st.session_state:
    st.session_state.scores = {"Content": 0, "Organization": 0, "Language": 0}

st.title("ğŸ¤– DSE AI è¶…çº§å¯¼å¸ˆ (Proç‰ˆ)")

col1, col2 = st.columns([1, 1])

with col1:
    st.markdown("### âœï¸ ç¬¬ä¸€æ­¥ï¼šæäº¤ä½œæ–‡")
    task_type = st.selectbox("é€‰æ‹©é¢˜å‹", ["Part A", "Part B", "Argumentative", "Letter to Editor"])
    target_lv = st.select_slider("ç›®æ ‡ç­‰çº§", options=["3", "4", "5", "5*", "5**"])
    user_text = st.text_area("ç²˜è´´ä½ çš„ä½œæ–‡å†…å®¹...", height=250)
    
    if st.button("ğŸš€ æ·±åº¦æ‰¹æ”¹æŠ¥å‘Š", use_container_width=True):
        if user_text:
            with st.spinner("é˜…å·å®˜æ­£åœ¨æ‰“åˆ†å¹¶ç»˜å›¾..."):
                # å¼ºåŒ–ç‰ˆ Promptï¼šå¼ºåˆ¶è¦æ±‚è¾“å‡ºåˆ†æ•°æ ‡ç­¾
                prompt = f"""
                ä½ æ˜¯ä¸€ä½ç²¾é€šDSEè¯„åˆ†æ ‡å‡†çš„è€ƒå®˜ã€‚è¯·å¯¹è¿™ç¯‡{task_type}ä½œæ–‡ç»™Level {target_lv}ç›®æ ‡çš„åŒå­¦å†™æ‰¹æ”¹æŠ¥å‘Šã€‚
                
                å¿…é¡»ä¸¥æ ¼éµå®ˆä»¥ä¸‹ä¸¤ä¸ªè¦æ±‚ï¼š
                1. åœ¨å›å¤çš„æœ€åä¸€è¡Œï¼Œå¿…é¡»æŒ‰ç…§æ­¤æ ¼å¼è¾“å‡ºåˆ†æ•°ï¼ˆæ¯é¡¹æ»¡åˆ†7åˆ†ï¼‰ï¼šSCORES: C:æ•°å­—, O:æ•°å­—, L:æ•°å­—
                2. ä½¿ç”¨ç¹ä½“ä¸­æ–‡ï¼Œæä¾›è¯„åˆ†ã€å»ºè®®ã€èŒƒæ–‡å’ŒKillerè¯æ±‡ã€‚
                
                ä½œæ–‡å†…å®¹ï¼š{user_text}
                """
                response = client.models.generate_content(model="gemini-3-flash-preview", contents=prompt)
                full_text = response.text
                
                # æå–åˆ†æ•°
                score_match = re.search(r"SCORES: C:(\d), O:(\d), L:(\d)", full_text)
                if score_match:
                    st.session_state.scores = {
                        "Content": int(score_match.group(1)),
                        "Organization": int(score_match.group(2)),
                        "Language": int(score_match.group(3))
                    }
                
                st.session_state.last_report = full_text.split("SCORES:")[0] # éšè—åŸå§‹åˆ†æ•°è¡Œ
                st.session_state.chat_history = [("AI", "æŠ¥å‘Šå·²ç”Ÿæˆï¼ä½ å¯ä»¥æ ¹æ®é›·è¾¾å›¾æŸ¥çœ‹å¼±é¡¹ï¼Œå¹¶å‘æˆ‘è¿½é—®ã€‚")]
        else:
            st.warning("è¯·è¾“å…¥å†…å®¹")

    if "last_report" in st.session_state:
        # ç»˜åˆ¶é›·è¾¾å›¾
        categories = list(st.session_state.scores.keys())
        values = list(st.session_state.scores.values())
        
        fig = go.Figure()
        fig.add_trace(go.Scatterpolar(r=values + [values[0]], theta=categories + [categories[0]], fill='toself', name='ä½ çš„è¡¨ç°'))
        fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 7])), showlegend=False, height=350)
        
        st.plotly_chart(fig, use_container_width=True)
        st.markdown(st.session_state.last_report)

with col2:
    st.markdown("### ğŸ’¬ ç¬¬äºŒæ­¥ï¼š1-on-1 è¿½é—®æ¨¡å¼")
    if "last_report" not in st.session_state:
        st.info("å®Œæˆå·¦ä¾§æ‰¹æ”¹åå¼€å¯å¯¹è¯ã€‚")
    else:
        for role, text in st.session_state.chat_history:
            with st.chat_message(role):
                st.write(text)
        
        if prompt_input := st.chat_input("é’ˆå¯¹æ‰¹æ”¹ç»“æœè¿½é—®..."):
            st.session_state.chat_history.append(("User", prompt_input))
            with st.chat_message("User"):
                st.write(prompt_input)
            
            with st.chat_message("AI"):
                context = f"ä½œæ–‡: {user_text}\næŠ¥å‘Š: {st.session_state.last_report}\né—®é¢˜: {prompt_input}"
                response = client.models.generate_content(model="gemini-3-flash-preview", contents=context)
                st.write(response.text)
                st.session_state.chat_history.append(("AI", response.text))
                # åœ¨åŸæœ‰ä»£ç çš„ col1 éƒ¨åˆ†ï¼Œå¢åŠ ä¸€ä¸ªæ–°çš„åŠŸèƒ½å—
with col1:
    st.markdown("---")
    st.markdown("### ğŸ’¡ é‡‘å¥å®éªŒå®¤ (Sentence Booster)")
    target_sentence = st.text_input("è¾“å…¥ä¸€ä¸ªæ™®é€šå¥å­ï¼Œæˆ‘å¸®ä½ å‡çº§æˆ 5** å¥å¼ï¼š", placeholder="ä¾‹å¦‚: Plastic bags are bad for the environment.")
    
    if st.button("âœ¨ ç¬é—´å‡çº§", use_container_width=True):
        if target_sentence:
            with st.spinner("æ­£åœ¨æ³¨å…¥ 5** çµé­‚..."):
                boost_prompt = f"ä½ æ˜¯ä¸€ä½ DSE è¡¥ä¹ åå¸ˆã€‚è¯·å°†ä»¥ä¸‹å¥å­å‡çº§ä¸º Level 5** æ°´å¹³ã€‚è¦æ±‚ï¼šä½¿ç”¨æ›´é«˜çº§çš„è¯æ±‡ï¼ˆKiller Vocabï¼‰ã€å¤æ‚çš„ä»å¥ç»“æ„ï¼Œå¹¶è§£é‡Šæ”¹å†™åçš„åŠ åˆ†ç‚¹ã€‚å¥å­ï¼š{target_sentence}"
                boost_response = client.models.generate_content(model="gemini-3-flash-preview", contents=boost_prompt)
                st.success("å‡çº§æˆåŠŸï¼")
                st.markdown(boost_response.text)

