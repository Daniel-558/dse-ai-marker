import streamlit as st
from google.genai import Client
import plotly.graph_objects as go
import re
from fpdf import FPDF
import io
import os
from datetime import datetime
from PIL import Image

# 1. é¡µé¢é…ç½®ä¸é«˜çº§ UI
st.set_page_config(page_title="DSE English All-in-One Pro", layout="wide")

st.markdown("""
    <style>
    .stApp { background: #f8fafc; }
    .main-header { background: linear-gradient(135deg, #1e293b 0%, #334155 100%); padding: 1.5rem; border-radius: 12px; color: white; text-align: center; margin-bottom: 20px; }
    /* é‡ç‚¹ï¼šæŠ¥å‘Šå®¹å™¨æ ·å¼ */
    .report-card { background: white; padding: 25px; border-radius: 15px; border-left: 6px solid #3b82f6; box-shadow: 0 4px 12px rgba(0,0,0,0.08); margin-top: 15px; }
    .stTabs [data-baseweb="tab-list"] { gap: 12px; }
    .stTabs [data-baseweb="tab"] { background-color: #f1f5f9; border-radius: 8px 8px 0 0; padding: 12px 20px; font-weight: bold; }
    .stTabs [aria-selected="true"] { background-color: #3b82f6 !important; color: white !important; }
    /* èŠå¤©æ°”æ³¡æ ·å¼ */
    .chat-bubble { padding: 10px; border-radius: 10px; margin-bottom: 10px; border: 1px solid #e2e8f0; }
    </style>
    """, unsafe_allow_html=True)

# 2. åˆå§‹åŒ–æŒä¹…åŒ–çŠ¶æ€ (è¿™æ˜¯ä¿®å¤æ¶ˆå¤±é—®é¢˜çš„å…³é”®)
if "p2_data" not in st.session_state:
    st.session_state.p2_data = {"report": "", "scores": {"C": 0, "O": 0, "L": 0}}
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# åˆå§‹åŒ– API
api_key_val = st.secrets.get("GEMINI_API_KEY", "")
@st.cache_resource
def get_client(key):
    return Client(api_key=key) if key else None
client = get_client(api_key_val)

# 3. PDF å¯¼å‡ºä¿®å¤é€»è¾‘
def safe_generate_pdf(report_text, scores):
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Helvetica", size=12)
    pdf.cell(0, 10, "DSE English Writing Diagnosis Report", ln=True, align='C')
    pdf.ln(10)
    pdf.cell(0, 10, f"Score: C:{scores['C']} O:{scores['O']} L:{scores['L']} | Total: {sum(scores.values())}/21", ln=True)
    pdf.ln(5)
    # è¿‡æ»¤æ‰æ— æ³•åœ¨æ ‡å‡† PDF ä¸­æ˜¾ç¤ºçš„ Unicode å­—ç¬¦ï¼Œé˜²æ­¢ FPDFUnicodeEncodingException
    safe_content = "".join([i if ord(i) < 128 else ' ' for i in report_text])
    pdf.multi_cell(0, 8, safe_content[:2000] + "\n\n[Please view full Chinese details on the web portal]")
    return pdf.output()

# 4. ä¾§è¾¹æ ï¼šå…¨å±€å·¥å…·
with st.sidebar:
    st.title("ğŸ” DSE Portal")
    if st.text_input("è§£é”ç ", type="password") != "DSE2026":
        st.info("éªŒè¯ä»¥è§£é” P1-P4 å…¨åŠŸèƒ½")
        st.stop()
    
    st.markdown("---")
    days = (datetime(2026, 4, 10) - datetime.now()).days
    st.metric("DSE 2026 å€’æ•°", f"{days} å¤©")
    
    st.markdown("---")
    st.subheader("ğŸ“‚ èµ„æ–™ä¸Šä¼  (è¯†å›¾/PDF)")
    up_file = st.file_uploader("æ”¯æŒï¼šä½œæ–‡ç…§ç‰‡ã€é˜…è¯»æ–‡æœ¬ã€Data File", type=['png', 'jpg', 'jpeg', 'pdf'])
    
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰è®°å½•"):
        st.session_state.p2_data = {"report": "", "scores": {"C": 0, "O": 0, "L": 0}}
        st.session_state.chat_history = []
        st.rerun()

# 5. ä¸»é¡µé¢å¸ƒå±€ï¼šå·¦åŠŸèƒ½åŒº | å³ç­”ç–‘åŒº
st.markdown('<div class="main-header"><h1>ğŸ‡¬ğŸ‡§ DSE English AI è¶…çº§å¯¼å¸ˆ Pro</h1><p>Reading â€¢ Writing â€¢ Integrated â€¢ Speaking å…¨èƒ½å·¥ä½œç«™</p></div>', unsafe_allow_html=True)

left_col, right_col = st.columns([1.3, 0.7], gap="large")

# --- å·¦ä¾§ï¼šæ ¸å¿ƒåŠŸèƒ½ Tabs ---
with left_col:
    tabs = st.tabs(["ğŸ“– P1 Reading", "âœï¸ P2 Writing", "ğŸ§ P3 Integrated", "ğŸ—£ï¸ P4 Speaking"])

    # --- P1: Reading ---
    with tabs[0]:
        st.markdown("### ğŸ” Reading é€»è¾‘æ‹†è§£")
        p1_input = st.text_area("è¾“å…¥å¤æ‚å¥å­æˆ–æ®µè½ï¼š", height=150, placeholder="Once you paste a sentence here...", key="p1_txt")
        if st.button("AI æ·±åº¦æ‹†è§£"):
            with st.spinner("åˆ†æä¸­..."):
                res = client.models.generate_content(model="gemini-2.0-flash", contents=f"è§£æDSEé–±è®€ï¼š1.ç¿»è­¯ 2.å¥æ³•æ‹†è§£ 3.é æ¸¬è€ƒé»ã€‚åŸæ–‡ï¼š{p1_input}")
                st.info(res.text)

    # --- P2: Writing (ä¿®å¤æ ¸å¿ƒï¼šæŒä¹…åŒ–æ˜¾ç¤ºæŠ¥å‘Š) ---
    with tabs[1]:
        st.markdown("### âœï¸ ä½œæ–‡æ·±åº¦æ‰¹æ”¹ä¸ 5** èŒƒæ–‡")
        p2_part = st.radio("é€‰æ‹©è€ƒéƒ¨åˆ†", ["Part A (Short)", "Part B (Long)"], horizontal=True)
        target_lv = st.select_slider("ç›®æ ‡ç­‰çº§", options=["3", "4", "5", "5*", "5**"])
        user_p2 = st.text_area("åœ¨æ­¤è¾“å…¥ä½œæ–‡å†…å®¹...", height=250, placeholder="Start writing here...", key="p2_txt")
        
        if st.button("ğŸš€ å¼€å§‹ AI è¯†å›¾ä¸æ·±åº¦æ‰¹æ”¹"):
            with st.spinner("é˜…å·ä¸»å¸­è¯„åˆ†ä¸­..."):
                prompt = f"""ä½ æ˜¯ä¸€ä½è³‡æ·±DSEé–±å·ä¸»å¸­ã€‚æ‰¹æ”¹é€™ç¯‡ {p2_part} ä½œæ–‡ï¼Œç›®æ¨™ {target_lv}ã€‚
                å…§å®¹é ˆåŒ…å«ï¼š1.ç­‰ç´šè©•ä¼° 2.åˆ†é …åˆ†æ(C/O/L) 3.5**ç¯„æ–‡ç¤ºç¯„ 4.æ”¹é€²å»ºè­°ã€‚
                æœ€å¾Œä¸€è¡Œè¼¸å‡ºï¼šSCORES: C:æ•¸å­—, O:æ•¸å­—, L:æ•¸å­—ã€‚ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚"""
                inputs = [prompt, user_p2]
                if up_file: inputs.append(Image.open(up_file))
                
                response = client.models.generate_content(model="gemini-2.0-flash", contents=inputs)
                st.session_state.p2_data["report"] = response.text
                
                # æå–åˆ†æ•°
                match = re.search(r"SCORES: C:(\d), O:(\d), L:(\d)", response.text)
                if match:
                    st.session_state.p2_data["scores"] = {"C": int(match.group(1)), "O": int(match.group(2)), "L": int(match.group(3))}

        # ï¼ï¼ä¿®å¤ç‚¹ï¼šåªè¦æœ‰æŠ¥å‘Šï¼Œåˆ‡æ¢ Tab å›æ¥ä¾ç„¶æ˜¾ç¤º ï¼ï¼
        if st.session_state.p2_data["report"]:
            st.markdown("---")
            rep_col, chart_col = st.columns([2, 1])
            with rep_col:
                st.subheader(f"æ‰¹æ”¹ç»“æœ (æ€»åˆ†: {sum(st.session_state.p2_data['scores'].values())}/21)")
                # PDF å¯¼å‡ºæŒ‰é’®
                try:
                    pdf_bytes = safe_generate_pdf(st.session_state.p2_data["report"], st.session_state.p2_data["scores"])
                    st.download_button("ğŸ“¥ ä¸‹è½½ 5** è¯Šæ–­æŠ¥å‘Š", data=pdf_bytes, file_name="DSE_Writing_Report.pdf")
                except: pass
            with chart_col:
                # é›·è¾¾å›¾å¯è§†åŒ–
                s = st.session_state.p2_data["scores"]
                fig = go.Figure(data=go.Scatterpolar(r=[s['C'], s['O'], s['L'], s['C']], theta=['C','O','L','C'], fill='toself', line_color='#3b82f6'))
                fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 7])), height=250, margin=dict(t=30, b=30, l=30, r=30))
                st.plotly_chart(fig, use_container_width=True)
            
            st.markdown(f'<div class="report-card">{st.session_state.p2_data["report"]}</div>', unsafe_allow_html=True)

    # --- P3: Integrated ---
    with tabs[2]:
        st.markdown("### ğŸ§ P3 æ ¼å¼åº“ä¸æ•´åˆæŠ€å·§")
        p3_type = st.selectbox("é€‰æ‹©ä»»åŠ¡ç±»å‹", ["Formal Letter", "Report", "Proposal", "Article", "Email"])
        if st.button("è·å– 5** æ ¼å¼æ¨¡æ¿"):
            res = client.models.generate_content(model="gemini-2.0-flash", contents=f"æä¾›DSE P3 {p3_type} çš„æ¨™å‡†æ ¼å¼ã€å¸¸ç”¨å¥å¼åŠ Data File æ•´åˆæŠ€å·§ã€‚")
            st.success(res.text)

    # --- P4: Speaking ---
    with tabs[3]:
        st.markdown("### ğŸ—£ï¸ Speaking è®ºç‚¹ç”Ÿæˆå™¨")
        spk_topic = st.text_input("è¾“å…¥å£è¯•é¢˜ç›®ï¼š", placeholder="e.g. Mandatory garbage bags in HK")
        if st.button("è„‘æš´ 5** è§‚ç‚¹"):
            res = client.models.generate_content(model="gemini-2.0-flash", contents=f"é‡å°'{spk_topic}'æä¾›3å€‹å…·å‚™æ·±åº¦çš„è«–é»ã€é«˜ç´šè©å½™åŠè½‰æŠ˜é‡‘å¥ã€‚")
            st.info(res.text)

# --- å³ä¾§ï¼šå…¨å·é€šç”¨å¯¼å¸ˆç­”ç–‘ ---
with right_col:
    st.markdown("### ğŸ’¬ å¯¼å¸ˆå®æ—¶ç­”ç–‘ (1-on-1)")
    st.caption("ä½ å¯ä»¥åœ¨æ­¤é’ˆå¯¹ Paper 1-4 çš„ä»»ä½•é—®é¢˜è¿›è¡Œè¿½é—®ã€‚")
    
    chat_container = st.container(height=550, border=True)
    with chat_container:
        if not st.session_state.chat_history:
            st.info("ğŸ‘‹ ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„ DSE AI å¯¼å¸ˆã€‚ä½ å¯ä»¥é—®æˆ‘ï¼š\n- ä¸ºä»€ä¹ˆæˆ‘è¿™ç¯‡ä½œæ–‡çš„ Language åªæœ‰ 4 åˆ†ï¼Ÿ\n- è¿™ä¸ª Reading éš¾å¥æ€ä¹ˆç†è§£ï¼Ÿ\n- P3 çš„ Data File æ€ä¹ˆæ•´åˆï¼Ÿ")
        for role, text in st.session_state.chat_history:
            with st.chat_message(role):
                st.write(text)

    if q_input := st.chat_input("é’ˆå¯¹æ‰¹æ”¹æŠ¥å‘Šæˆ–è€ƒè¯•å†…å®¹æé—®..."):
        st.session_state.chat_history.append(("user", q_input))
        # è‡ªåŠ¨æºå¸¦ Paper 2 çš„ä¸Šä¸‹æ–‡
        ctx = f"å½“å‰æ‰¹æ”¹æŠ¥å‘Šå†…å®¹ï¼š{st.session_state.p2_data['report']}" if st.session_state.p2_data['report'] else "æš‚æ— æ‰¹æ”¹æŠ¥å‘Š"
        full_prompt = f"ä¸Šä¸‹æ–‡ï¼š{ctx}\n\nå­¦ç”Ÿé—®é¢˜ï¼š{q_input}"
        
        with st.chat_message("user"): st.write(q_input)
        response = client.models.generate_content(model="gemini-2.0-flash", contents=full_prompt)
        st.session_state.chat_history.append(("assistant", response.text))
        st.rerun()
