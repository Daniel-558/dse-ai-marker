import streamlit as st
from google.genai import Client
import plotly.graph_objects as go
import re
import numpy as np
from datetime import datetime
from PIL import Image
from fpdf import FPDF
import io

# --- 1. é é¢é…ç½®èˆ‡å…¨å±€æ¨£å¼ ---
st.set_page_config(page_title="DSE AI è¶…ç´šå·¥ä½œç«™", layout="wide")

st.markdown("""
    <style>
    .stApp { background: #f8fafc; }
    .main-header { padding: 1.5rem; border-radius: 12px; color: white; text-align: center; margin-bottom: 20px; box-shadow: 0 4px 15px rgba(0,0,0,0.1); }
    .eng-theme { background: linear-gradient(135deg, #1e293b 0%, #334155 100%); }
    .math-theme { background: linear-gradient(135deg, #064e3b 0%, #059669 100%); }
    .report-card { background: white; padding: 25px; border-radius: 15px; border-left: 6px solid #3b82f6; box-shadow: 0 4px 12px rgba(0,0,0,0.05); margin-top: 15px; white-space: pre-wrap; }
    .stTabs [data-baseweb="tab-list"] { gap: 10px; }
    .stTabs [data-baseweb="tab"] { background-color: #f1f5f9; border-radius: 8px 8px 0 0; padding: 12px 20px; font-weight: bold; }
    .stTabs [aria-selected="true"] { background-color: #3b82f6 !important; color: white !important; }
    </style>
    """, unsafe_allow_html=True)

# --- 2. ç‹€æ…‹ç®¡ç† (ç¢ºä¿åˆ‡æ›å­¸ç§‘ä¸ä¸Ÿå¤±æ•¸æ“š) ---
if "eng_data" not in st.session_state:
    st.session_state.eng_data = {"report": "", "scores": {"C": 0, "O": 0, "L": 0}}
if "math_data" not in st.session_state:
    st.session_state.math_data = {"solution": ""}
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# API åˆå§‹åŒ–
api_key_val = st.secrets.get("GEMINI_API_KEY", "")
@st.cache_resource
def get_client(key):
    return Client(api_key=key) if key else None
client = get_client(api_key_val)

# PDF å°å‡ºè¼”åŠ©å‡½æ•¸
def generate_pdf_report(report_text, scores):
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Helvetica", size=12)
    pdf.cell(0, 10, "DSE English Writing Diagnosis", ln=True, align='C')
    pdf.ln(5)
    pdf.cell(0, 10, f"Scores -> C:{scores['C']} O:{scores['O']} L:{scores['L']}", ln=True)
    safe_text = "".join([i if ord(i) < 128 else ' ' for i in report_text])
    pdf.multi_cell(0, 8, safe_text[:2000])
    return pdf.output()

# --- 3. å´é‚Šæ¬„ ---
with st.sidebar:
    st.title("ğŸ›¡ï¸ DSE Portal")
    if st.text_input("è§£é–ç¢¼", type="password") != "DSE2026":
        st.stop()
    
    st.markdown("---")
    subject = st.selectbox("ğŸ“š é¸æ“‡å‚™è€ƒç§‘ç›®", ["ğŸ‡¬ğŸ‡§ English Language", "ğŸ”¢ Mathematics"])
    
    st.markdown("---")
    st.subheader("ğŸ“‚ æª”æ¡ˆä¸Šå‚³ (ä½œæ–‡ç…§ç‰‡/æ•¸å­¸é¡Œ)")
    up_file = st.file_uploader("æ”¯æ´ JPG/PNG/PDF", type=['png', 'jpg', 'jpeg', 'pdf'])
    
    if st.button("ğŸ—‘ï¸ å¾¹åº•æ¸…ç©ºè¨˜éŒ„"):
        for key in ["eng_data", "math_data", "chat_history"]:
            if key in st.session_state: del st.session_state[key]
        st.rerun()

# --- 4. ä¸»ç•Œé¢ä½ˆå±€ ---
theme = "eng-theme" if "English" in subject else "math-theme"
st.markdown(f'<div class="main-header {theme}"><h1>{subject} AI è¶…ç´šå°å¸« Pro</h1><p>å…¨ç§‘ä¸€ç«™å¼å‚™è€ƒç³»çµ±</p></div>', unsafe_allow_html=True)

main_col, chat_col = st.columns([1.3, 0.7], gap="large")

# ==========================================
# ğŸ  è‹±æ–‡ç§‘æ¨¡å¡Š (English Language)
# ==========================================
if "English" in subject:
    with main_col:
        tabs = st.tabs(["ğŸ“– P1 Reading", "âœï¸ P2 Writing", "ğŸ§ P3 Integrated", "ğŸ—£ï¸ P4 Speaking"])
        
        with tabs[0]:
            st.markdown("### ğŸ” Reading é‚è¼¯æ‹†è§£")
            p1_in = st.text_area("è¼¸å…¥é›£å¥ï¼š", height=100, key="e_p1")
            if st.button("AI æ‹†è§£æ€è·¯", key="e_p1_btn"):
                res = client.models.generate_content(model="gemini-2.0-flash", contents=f"è§£æDSEé–±è®€ï¼š1.ç¿»è­¯ 2.å¥æ³• 3.è€ƒé»ã€‚åŸæ–‡ï¼š{p1_in}")
                st.info(res.text)

        with tabs[1]:
            st.markdown("### âœï¸ Writing æ·±åº¦æ‰¹æ”¹")
            p2_part = st.radio("é¸æ“‡éƒ¨åˆ†", ["Part A", "Part B"], horizontal=True)
            user_p2 = st.text_area("åœ¨æ­¤ç²˜è²¼ä½œæ–‡...", height=250, key="e_p2_in")
            if st.button("ğŸš€ å•Ÿå‹•æ‰¹æ”¹"):
                with st.spinner("é–±å·ä¸»å¸­è©•åˆ†ä¸­..."):
                    prompt = f"ä½ æ˜¯ä¸€ä½DSEé–±å·ä¸»å¸­ã€‚æ‰¹æ”¹é€™ç¯‡ {p2_part} ä½œæ–‡ã€‚æä¾›ç­‰ç´šè©•ä¼°ã€C/O/Lç´°é …åˆ†ã€200å­—5**ç¯„æ–‡ã€‚æœ€å¾Œä¸€è¡Œè¼¸å‡º: SCORES: C:æ•¸å­—, O:æ•¸å­—, L:æ•¸å­—ã€‚"
                    inputs = [prompt, user_p2]
                    if up_file: inputs.append(Image.open(up_file))
                    resp = client.models.generate_content(model="gemini-2.0-flash", contents=inputs)
                    st.session_state.eng_data["report"] = resp.text
                    m = re.search(r"SCORES: C:(\d), O:(\d), L:(\d)", resp.text)
                    if m: st.session_state.eng_data["scores"] = {"C": int(m.group(1)), "O": int(m.group(2)), "L": int(m.group(3))}
            
            if st.session_state.eng_data["report"]:
                st.markdown("---")
                sc = st.session_state.eng_data["scores"]
                c1, c2 = st.columns([1, 1])
                with c1:
                    st.subheader(f"å¾—åˆ†: {sum(sc.values())}/21")
                    fig = go.Figure(data=go.Scatterpolar(r=[sc['C'], sc['O'], sc['L'], sc['C']], theta=['Content','Org','Lang','Content'], fill='toself'))
                    fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 7])), height=280, margin=dict(t=30, b=30))
                    st.plotly_chart(fig, use_container_width=True)
                with c2:
                    pdf_b = generate_pdf_report(st.session_state.eng_data["report"], sc)
                    st.download_button("ğŸ“¥ ä¸‹è¼‰è¨ºæ–·å ±å‘Š", data=pdf_b, file_name="DSE_English_Report.pdf")
                st.markdown(f'<div class="report-card">{st.session_state.eng_data["report"]}</div>', unsafe_allow_html=True)

        with tabs[2]:
            st.markdown("### ğŸ§ P3 Integrated æ ¼å¼åº«")
            p3_t = st.selectbox("ä»»å‹™æ–‡é«”", ["Formal Letter", "Report", "Proposal", "Article"])
            if st.button("ç”Ÿæˆ 5** æ ¼å¼æ¨¡æ¿"):
                res = client.models.generate_content(model="gemini-2.0-flash", contents=f"çµ¦å‡ºDSE P3 {p3_t} çš„5**æ ¼å¼åŠå¸¸ç”¨å¥å¼ã€‚")
                st.success(res.text)

        with tabs[3]:
            st.markdown("### ğŸ—£ï¸ Speaking éˆæ„Ÿåº«")
            s_topic = st.text_input("è¼¸å…¥é¡Œç›®ï¼š")
            if st.button("è…¦æš´ 5** è«–é»"):
                res = client.models.generate_content(model="gemini-2.0-flash", contents=f"é‡å°é¡Œ '{s_topic}' æä¾›3å€‹æ·±åº¦è«–é»åŠè½‰æŠ˜å¥ã€‚")
                st.info(res.text)

# ==========================================
# ğŸ“ æ•¸å­¸ç§‘æ¨¡å¡Š (Mathematics)
# ==========================================
else:
    with main_col:
        tabs = st.tabs(["ğŸ“ Paper 1 è§£ç­”", "ğŸ¯ Paper 2 MC æŠ€å·§", "ğŸ“Š å‡½æ•¸ç¹ªåœ–", "ğŸ“š å¿…èƒŒå…¬å¼"])
        
        with tabs[0]:
            st.markdown("### ğŸ“ Step-by-Step é¡Œç›®æ‹†è§£")
            m_q = st.text_area("è¼¸å…¥é¡Œç›®æˆ–ä¸Šå‚³ç…§ç‰‡ï¼š", height=150, key="m_p1")
            if st.button("ğŸš€ ç”Ÿæˆè©³ç´°è§£é¡Œæ­¥é©Ÿ"):
                with st.spinner("AI æ­£åœ¨æ¨ç®—..."):
                    prompt = "ä½ æ˜¯ä¸€ä½DSEæ•¸å­¸åå¸«ã€‚è«‹åˆ†æ­¥è§£ç­”æ­¤é¡Œï¼ŒåŒ…å«è€ƒé»åˆ†æã€è©³ç´°æ­¥é©Ÿ(ä½¿ç”¨LaTeX)åŠå¥ªæ˜Ÿäº®é»ã€‚ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚"
                    inputs = [prompt, m_q]
                    if up_file: inputs.append(Image.open(up_file))
                    res = client.models.generate_content(model="gemini-2.0-flash", contents=inputs)
                    st.session_state.math_data["solution"] = res.text
            if st.session_state.math_data["solution"]:
                st.markdown(f'<div class="report-card">{st.session_state.math_data["solution"]}</div>', unsafe_allow_html=True)

        with tabs[1]:
            st.markdown("### ğŸ¯ MC ç§’æ®ºæŠ€å·§åº«")
            mc_cat = st.selectbox("æŠ€å·§é¡å‹", ["ä»£å…¥æ³• (Substitution)", "ä¼°ç®—æ³• (Estimation)", "è¨ˆæ•¸æ©Ÿç¨‹åº (Calculator)"])
            if st.button("ç²å–ç§’æ®ºç¯„ä¾‹"):
                res = client.models.generate_content(model="gemini-2.0-flash", contents=f"è§£é‡‹DSEæ•¸å­¸MCä¸­ '{mc_cat}' çš„æ‡‰ç”¨åŠç¶“å…¸é¡Œå‹ã€‚")
                st.success(res.text)

        with tabs[2]:
            st.markdown("### ğŸ“Š äºŒæ¬¡å‡½æ•¸ç¹ªåœ–å™¨")
            ca, cb, cc = st.columns(3)
            a = ca.number_input("a (äºŒæ¬¡é …)", value=1.0)
            b = cb.number_input("b (ä¸€æ¬¡é …)", value=0.0)
            c = cc.number_input("c (å¸¸æ•¸é …)", value=0.0)
            x_vals = np.linspace(-10, 10, 400)
            y_vals = a*x_vals**2 + b*x_vals + c
            fig = go.Figure(data=go.Scatter(x=x_vals, y=y_vals, name="f(x)"))
            fig.update_layout(title=f"y = {a}xÂ² + {b}x + {c}", height=350)
            st.plotly_chart(fig, use_container_width=True)
            st.latex(rf"y = {a}x^2 + {b}x + {c}")

        with tabs[3]:
            st.subheader("ğŸ“š æ ¸å¿ƒå…¬å¼å¡")
            st.latex(r"\text{Quadratic Formula: } x = \frac{-b \pm \sqrt{b^2-4ac}}{2a}")
            st.latex(r"\text{Cosine Law: } c^2 = a^2 + b^2 - 2ab\cos C")

# ==========================================
# ğŸ’¬ å³å´ï¼šå…¨å·é€šç”¨å°å¸«ç­”ç–‘
# ==========================================
with chat_col:
    st.markdown(f"### ğŸ’¬ {subject} å°å¸«åœ¨ç·š")
    st.caption("æ‚¨å¯ä»¥éš¨æ™‚è¿½å•ä¸Šè¿°å…§å®¹ã€‚")
    chat_box = st.container(height=550, border=True)
    with chat_box:
        for r, t in st.session_state.chat_history:
            with st.chat_message(r): st.write(t)
            
    if q := st.chat_input("è¼¸å…¥æ‚¨çš„å•é¡Œ..."):
        st.session_state.chat_history.append(("user", q))
        with st.chat_message("user"): st.write(q)
        
        # æ ¹æ“šç§‘ç›®ç²å–ä¸Šä¸‹æ–‡
        ctx = st.session_state.eng_data["report"] if "English" in subject else st.session_state.math_data["solution"]
        prompt = f"ä½ æ˜¯DSE {subject}å°ˆå®¶ã€‚åƒè€ƒå…§å®¹ï¼š{ctx}\n\nå­¸ç”Ÿå•é¡Œï¼š{q}"
        
        response = client.models.generate_content(model="gemini-2.0-flash", contents=prompt)
        st.session_state.chat_history.append(("assistant", response.text))
        st.rerun()
