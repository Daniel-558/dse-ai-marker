import streamlit as st
from google.genai import Client
import plotly.graph_objects as go
import re

# 1. é é¢é…ç½®
st.set_page_config(page_title="DSE AI è¶…ç´šå°å¸« Pro", layout="wide")

# 2. è‡ªå®šç¾© CSS æ¨£å¼
st.markdown("""
    <style>
    .stApp { background-color: #f8f9fa; }
    h1 { color: #1e3a8a !important; font-weight: 800; border-bottom: 3px solid #fbbf24; padding-bottom: 10px; }
    .stButton>button { 
        background-color: #1e3a8a; color: white; border-radius: 8px; 
        font-weight: bold; width: 100%; transition: 0.3s;
    }
    .stButton>button:hover { background-color: #fbbf24; color: #1e3a8a; }
    .stChatMessage { border-radius: 15px; margin-bottom: 10px; }
    .report-card { 
        background-color: white; padding: 20px; border-radius: 12px; 
        box-shadow: 0 2px 4px rgba(0,0,0,0.05); border-left: 5px solid #fbbf24;
    }
    </style>
    """, unsafe_allow_html=True)

# 3. åˆå§‹åŒ– API å®¢æˆ·ç«¯
# é€™è£¡æœƒå¾ Streamlit Secrets ä¸­è®€å–å¯†é‘°èˆ‡é‚€è«‹ç¢¼
api_key_val = st.secrets.get("GEMINI_API_KEY", "")
correct_code = st.secrets.get("ACCESS_CODE", "") # é‚€è«‹ç¢¼ç¾åœ¨å„²å­˜åœ¨ Secretï¼Œä»£ç¢¼ä¸­ä¸é¡¯ç¤º

@st.cache_resource
def get_client(key):
    return Client(api_key=key) if key else None

client = get_client(api_key_val)

# 4. åˆå§‹åŒ–ç‹€æ…‹è®Šé‡
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "scores" not in st.session_state:
    st.session_state.scores = {"Content": 0, "Organization": 0, "Language": 0}
if "last_report" not in st.session_state:
    st.session_state.last_report = ""
if "essay_text" not in st.session_state:
    st.session_state.essay_text = ""

# 5. å´é‚Šæ¬„ï¼šé©—è­‰é‚è¼¯
with st.sidebar:
    st.title("ğŸ” å°å¸«æ¥å…¥é¢æ¿")
    access_code = st.text_input("è«‹è¼¸å…¥é‚€è«‹ç¢¼è§£é–", type="password")
    
    # é€™è£¡æœƒèˆ‡ä½ è¨­å®šåœ¨ Secret çš„ ACCESS_CODE é€²è¡Œæ¯”å°
    if access_code != correct_code:
        st.warning("ğŸ”’ è«‹è¼¸å…¥æ­£ç¢ºé‚€è«‹ç¢¼ä»¥è§£é– AI åŠŸèƒ½ã€‚")
        st.stop()
    
    st.success("âœ… é©—è­‰æˆåŠŸï¼")
    st.divider()
    st.title("ğŸ“š DSE æåˆ†å·¥å…·")
    with st.expander("5** å¿…èƒŒé€£è©"):
        st.markdown("- **Paradoxically**\n- **Notwithstanding**\n- **In tandem with**")

# 6. ä¸»ç•Œé¢ä½ˆå±€
st.title("ğŸ¤– DSE AI è¶…ç´šå°å¸« Pro")
st.caption("åŸºæ–¼è€ƒå®˜é‚è¼¯çš„ 1-on-1 æ·±åº¦æ‰¹æ”¹èˆ‡äº’å‹•å¹³å°")

tab_marker, tab_lab = st.tabs(["ğŸ“ ä½œæ–‡æ·±åº¦æ‰¹æ”¹", "âœ¨ é‡‘å¥å¯¦é©—å®¤"])

# --- Tab 1: ä½œæ–‡æ‰¹æ”¹ ---
with tab_marker:
    col1, col2 = st.columns([1, 1], gap="large")

    with col1:
        st.markdown("### ğŸ“¥ ç¬¬ä¸€æ­¥ï¼šæäº¤ä½œæ–‡")
        task_type = st.selectbox("é¸æ“‡é¡Œå‹", ["Part A", "Part B", "Argumentative", "Letter to Editor"])
        target_lv = st.select_slider("ç›®æ¨™ç­‰ç´š", options=["3", "4", "5", "5*", "5**"])
        user_text = st.text_area("åœ¨æ­¤ç²˜è²¼ä½ çš„ä½œæ–‡...", height=300, value=st.session_state.essay_text)
        
        if st.button("ğŸš€ ç”Ÿæˆè€ƒå®˜ç´šæ‰¹æ”¹å ±å‘Š"):
            if user_text:
                st.session_state.essay_text = user_text
                with st.spinner("é–±å·å®˜æ­£åœ¨ç²¾ç¢ºæ‰“åˆ†ä¸¦æ’°å¯«å ±å‘Š..."):
                    prompt = f"""
                    ä½ æ˜¯ä¸€ä½ç²¾é€šé¦™æ¸¯ DSE è©•åˆ†æ¨™æº–çš„è‹±æ–‡ç§‘é–±å·å®˜ã€‚
                    è«‹å°é€™ç¯‡ {task_type} ä½œæ–‡çµ¦äºˆ Level {target_lv} ç›®æ¨™çš„åŒå­¸å¯«ä¸€ä»½è©³ç›¡å ±å‘Šã€‚
                    è¦æ±‚ï¼š
                    1. æŒ‡å‡º Content, Organization, Language ä¸‰æ–¹é¢çš„å…·é«”å„ªé»èˆ‡ç¼ºé»ã€‚
                    2. æä¾›ä¸€æ®µ Level 5** æ°´å¹³çš„ç¯„æ–‡æ”¹å¯«ã€‚
                    3. æœ€å¾Œä¸€è¡Œå¿…é ˆåš´æ ¼æŒ‰ç…§æ­¤æ ¼å¼è¼¸å‡ºåˆ†æ•¸ï¼šSCORES: C:æ•¸å­—, O:æ•¸å­—, L:æ•¸å­— (æ¯é …æ»¿åˆ† 7)
                    è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚
                    """
                    # ä½¿ç”¨æœ€æ–°çš„ 2.0 Flash æ¨¡å‹
                    response = client.models.generate_content(
                        model="gemini-2.0-flash", 
                        contents=[prompt, user_text]
                    )
                    full_text = response.text
                    
                    # æå–åˆ†æ•¸ä¸¦æ›´æ–°é›·é”åœ–
                    score_match = re.search(r"SCORES:\s*C:(\d),\s*O:(\d),\s*L:(\d)", full_text)
                    if score_match:
                        st.session_state.scores = {
                            "Content": int(score_match.group(1)),
                            "Organization": int(score_match.group(2)),
                            "Language": int(score_match.group(3))
                        }
                    
                    st.session_state.last_report = full_text.split("SCORES:")[0]
                    st.session_state.chat_history = [
                        {"role": "assistant", "content": "å ±å‘Šå·²ç”Ÿæˆï¼ä½ å¯ä»¥æŸ¥çœ‹å·¦å´çš„åˆ†æï¼Œä¸æ˜ç™½çš„åœ°æ–¹åœ¨å³å´éš¨æ™‚å•æˆ‘ã€‚"}
                    ]
            else:
                st.warning("è«‹å…ˆè¼¸å…¥å…§å®¹ã€‚")

        if st.session_state.last_report:
            st.markdown("---")
            categories = list(st.session_state.scores.keys())
            values = list(st.session_state.scores.values())
            fig = go.Figure(data=go.Scatterpolar(r=values + [values[0]], theta=categories + [categories[0]], fill='toself', line_color='#1e3a8a'))
            fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 7])), showlegend=False, height=350)
            st.plotly_chart(fig, use_container_width=True)
            
            st.markdown("### ğŸ“‹ æ‰¹æ”¹å ±å‘Šå…§å®¹")
            st.markdown(f'<div class="report-card">{st.session_state.last_report}</div>', unsafe_allow_html=True)

    with col2:
        st.markdown("### ğŸ’¬ ç¬¬äºŒæ­¥ï¼šå°å¸« 1-on-1 ç­”ç–‘")
        if not st.session_state.last_report:
            st.info("å®Œæˆå·¦å´æ‰¹æ”¹å¾Œï¼Œå°å¸«å°‡åœ¨æ­¤ç‚ºä½ è§£ç­”ç–‘å•ã€‚")
        else:
            for msg in st.session_state.chat_history:
                with st.chat_message(msg["role"]):
                    st.write(msg["content"])
            
            if prompt_input := st.chat_input("è€å¸«ï¼Œé€™æ®µæ”¹å¯«ç”¨äº†ä»€éº¼èªæ³•ï¼Ÿ"):
                st.session_state.chat_history.append({"role": "user", "content": prompt_input})
                with st.chat_message("user"):
                    st.write(prompt_input)
                
                with st.chat_message("assistant"):
                    with st.spinner("æ€è€ƒä¸­..."):
                        context = f"å­¸ç”ŸåŸæ–‡: {st.session_state.essay_text}\nå ±å‘Š: {st.session_state.last_report}\næå•: {prompt_input}"
                        response = client.models.generate_content(model="gemini-2.0-flash", contents=context)
                        st.write(response.text)
                        st.session_state.chat_history.append({"role": "assistant", "content": response.text})

# --- Tab 2: é‡‘å¥å¯¦é©—å®¤ ---
with tab_lab:
    st.markdown("### âœ¨ Level 5** é‡‘å¥å‡ç´šå¯¦é©—å®¤")
    s_input = st.text_input("è¼¸å…¥ä½ æƒ³å‡ç´šçš„å¥å­ï¼š")
    if st.button("âœ¨ ç¬é–“å‡ç´š"):
        if s_input:
            with st.spinner("æ­£åœ¨ç…‰é‡‘..."):
                lab_prompt = f"å°‡æ­¤å¥å­å‡ç´šç‚º DSE Level 5** æ°´å¹³ä¸¦è§£é‡‹åŠ åˆ†é»ï¼š{s_input}"
                res = client.models.generate_content(model="gemini-2.0-flash", contents=lab_prompt)
                st.success(res.text)
