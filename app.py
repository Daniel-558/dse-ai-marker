import streamlit as st
from google.genai import Client
import plotly.graph_objects as go
import re

# 1. é é¢é…ç½®
st.set_page_config(page_title="DSE AI è¶…ç´šå°å¸« Pro", layout="wide")

# 2. è‡ªå®šç¾©æ¨£å¼
st.markdown("""
    <style>
    .stApp { background-color: #f8f9fa; }
    h1 { color: #1e3a8a !important; font-weight: 800; border-bottom: 3px solid #fbbf24; padding-bottom: 10px; }
    .stChatMessage { border-radius: 15px; margin-bottom: 10px; }
    .report-card { 
        background-color: white; padding: 20px; border-radius: 12px; 
        box-shadow: 0 2px 4px rgba(0,0,0,0.05); border-left: 5px solid #fbbf24;
    }
    </style>
    """, unsafe_allow_html=True)

# 3. åˆå§‹åŒ– API å®¢æˆ¶ç«¯
# æé†’ï¼šè«‹ç¢ºä¿ä½ çš„ .streamlit/secrets.toml æœ‰ GEMINI_API_KEY
api_key = st.secrets.get("GEMINI_API_KEY", "")

@st.cache_resource
def get_client(key):
    return Client(api_key=key) if key else None

client = get_client(api_key)

# 4. å´é‚Šæ¬„ï¼šå·¥å…·ç®± (å·²ç§»é™¤é©—è­‰é‚è¼¯)
with st.sidebar:
    st.title("ğŸ“š DSE æåˆ†å·¥å…·")
    st.info("ğŸ’¡ æ­¡è¿ä½¿ç”¨ï¼ç›´æ¥åœ¨å³å´æäº¤ä½œæ–‡å³å¯é–‹å§‹æ‰¹æ”¹ã€‚")
    st.divider()
    with st.expander("5** å¿…èƒŒé€£è©"):
        st.markdown("- **Paradoxically**\n- **Notwithstanding**\n- **In tandem with**")
    with st.expander("è©å½™å‡ç´šè¡¨"):
        st.table({"æ™®é€š": ["Think", "Help", "Big"], "5**ç´šåˆ¥": ["Advocate", "Facilitate", "Substantial"]})

# 5. ä¸»ç•«é¢é‚è¼¯
# åˆå§‹åŒ–ç‹€æ…‹è®Šé‡
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "scores" not in st.session_state:
    st.session_state.scores = {"Content": 0, "Organization": 0, "Language": 0}
if "last_report" not in st.session_state:
    st.session_state.last_report = ""

st.title("ğŸ¤– DSE AI è¶…ç´šå°å¸« Pro")
st.caption("å…¨æ¸¯é¦–å€‹åŸºæ–¼è€ƒå®˜é‚è¼¯çš„ AI äº’å‹•æ‰¹æ”¹å¹³å°")

# å¦‚æœ API Key ç¼ºå¤±çš„è­¦å‘Š
if not client:
    st.error("âš ï¸ åµæ¸¬ä¸åˆ° API Keyã€‚è«‹ç¢ºä¿ .streamlit/secrets.toml ä¸­è¨­å®šäº† GEMINI_API_KEYã€‚")
    st.stop()

tab1, tab2 = st.tabs(["ğŸ“ ä½œæ–‡æ·±åº¦æ‰¹æ”¹", "âœ¨ é‡‘å¥å¯¦é©—å®¤"])

# --- Tab 1: ä½œæ–‡æ‰¹æ”¹ ---
with tab1:
    col1, col2 = st.columns([1, 1], gap="large")

    with col1:
        st.markdown("### ğŸ“¥ æäº¤ä½œæ–‡")
        task_type = st.selectbox("é¸æ“‡é¡Œå‹", ["Part A", "Part B", "Argumentative", "Letter to Editor"])
        target_lv = st.select_slider("ç›®æ¨™ç­‰ç´š", options=["3", "4", "5", "5*", "5**"])
        user_text = st.text_area("åœ¨æ­¤ç²˜è²¼ä½ çš„ä½œæ–‡...", height=300)
        
        if st.button("ğŸš€ ç”Ÿæˆæ·±åº¦æ‰¹æ”¹å ±å‘Š"):
            if user_text:
                with st.spinner("é–±å·å®˜æ­£åœ¨ç²¾ç¢ºæ‰“åˆ†..."):
                    prompt = f"ä½ æ˜¯ä¸€ä½ç²¾é€šé¦™æ¸¯ DSE è©•åˆ†æ¨™æº–çš„é–±å·å®˜ã€‚è«‹å°é€™ç¯‡ {task_type} ä½œæ–‡çµ¦äºˆ Level {target_lv} çš„ç¹é«”ä¸­æ–‡å ±å‘Šã€‚æœ€å¾Œä¸€è¡Œå¿…é ˆè¼¸å‡ºï¼šSCORES: C:æ•¸å­—, O:æ•¸å­—, L:æ•¸å­— (æ¯é …æ»¿åˆ† 7)"
                    response = client.models.generate_content(model="gemini-2.0-flash", contents=[prompt, user_text])
                    
                    full_text = response.text
                    # æå–åˆ†æ•¸ä¸¦æ›´æ–°é›·é”åœ–
                    score_match = re.search(r"SCORES:\s*C:(\d),\s*O:(\d),\s*L:(\d)", full_text)
                    if score_match:
                        st.session_state.scores = {
                            "Content": int(score_match.group(1)),
                            "Organization": int(score_match.group(2)),
                            "Language": int(score_match.group(3))
                        }
                    st.session_state.last_report = full_text.split("SCORES:")[0]
                    st.session_state.chat_history = [{"role": "assistant", "content": "å ±å‘Šå·²ç”Ÿæˆï¼ä½ å¯ä»¥æŸ¥çœ‹åˆ†æï¼Œæœ‰ä¸æ˜ç™½çš„åœ°æ–¹åœ¨å³å´å•æˆ‘ã€‚"}]
            else:
                st.warning("è«‹å…ˆè¼¸å…¥ä½œæ–‡å…§å®¹ã€‚")

        if st.session_state.last_report:
            st.markdown("---")
            # é›·é”åœ–
            categories = list(st.session_state.scores.keys())
            values = list(st.session_state.scores.values())
            fig = go.Figure(data=go.Scatterpolar(r=values + [values[0]], theta=categories + [categories[0]], fill='toself', line_color='#1e3a8a'))
            fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 7])), showlegend=False, height=300)
            st.plotly_chart(fig, use_container_width=True)
            st.markdown(f'<div class="report-card">{st.session_state.last_report}</div>', unsafe_allow_html=True)

    with col2:
        st.markdown("### ğŸ’¬ 1-on-1 å°å¸«ç­”ç–‘")
        if not st.session_state.last_report:
            st.info("æ‰¹æ”¹å®Œæˆå¾Œï¼Œå°å¸«æœƒåœ¨æ­¤ç‚ºä½ è§£ç­”ã€‚")
        else:
            for msg in st.session_state.chat_history:
                with st.chat_message(msg["role"]): st.write(msg["content"])
            
            if prompt_input := st.chat_input("è€å¸«ï¼Œé€™æ®µé»è§£å’æ”¹ï¼Ÿ"):
                st.session_state.chat_history.append({"role": "user", "content": prompt_input})
                with st.chat_message("user"): st.write(prompt_input)
                
                with st.chat_message("assistant"):
                    context = f"åŸæ–‡å…§å®¹: {user_text}\næ‰¹æ”¹å ±å‘Š: {st.session_state.last_report}\nå­¸ç”Ÿæå•: {prompt_input}"
                    res = client.models.generate_content(model="gemini-2.0-flash", contents=context)
                    st.write(res.text)
                    st.session_state.chat_history.append({"role": "assistant", "content": res.text})

# --- Tab 2: é‡‘å¥å¯¦é©—å®¤ ---
with tab2:
    st.markdown("### âœ¨ Level 5** é‡‘å¥å‡ç´šå¯¦é©—å®¤")
    st.write("è¼¸å…¥ä¸€å€‹æ™®é€šçš„å¥å­ï¼Œè®“ AI å¹«ä½ å‡ç´šæˆ 5** æ°´å¹³çš„é«˜ç´šè¡¨é”ã€‚")
    
    s_input = st.text_input("è¼¸å…¥ä½ æƒ³å‡ç´šçš„å¥å­ï¼š", placeholder="e.g. Many people agree that technology is important.")
    
    if st.button("âœ¨ ç¬é–“å‡ç´š"):
        if s_input:
            with st.spinner("æ­£åœ¨å„ªåŒ–èªè¨€çµæ§‹..."):
                lab_prompt = f"å°‡æ­¤å¥å­æ”¹å¯«ç‚º DSE Level 5** æ°´å¹³çš„é«˜ç´šè‹±èªï¼Œä½¿ç”¨é«˜ç´šè©å½™å’Œå¥å¼ï¼Œä¸¦ç”¨ç¹é«”ä¸­æ–‡è§£é‡‹åŠ åˆ†é»ï¼š{s_input}"
                res = client.models.generate_content(model="gemini-2.0-flash", contents=lab_prompt)
                st.success("å‡ç´šæˆåŠŸï¼")
                st.markdown(f'<div class="report-card">{res.text}</div>', unsafe_allow_html=True)
        else:
            st.warning("è«‹è¼¸å…¥å…§å®¹ã€‚")
