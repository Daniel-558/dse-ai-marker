import streamlit as st
from google.genai import Client
import plotly.graph_objects as go
import re

# 1. é¡µé¢é…ç½®
st.set_page_config(page_title="DSE AI è¶…çº§å¯¼å¸ˆ Pro", layout="wide")

# 2. è‡ªå®šä¹‰ CSS
st.markdown("""
    <style>
    .stApp { background-color: #f8f9fa; }
    h1 { color: #1e3a8a !important; font-weight: 800; border-bottom: 3px solid #fbbf24; padding-bottom: 10px; }
    .stButton>button { background-color: #1e3a8a; color: white; border-radius: 8px; font-weight: bold; width: 100%; }
    .stChatMessage { border-radius: 15px; margin-bottom: 10px; }
    /* é™åˆ¶é›·è¾¾å›¾å®¹å™¨é«˜åº¦ */
    .radar-container { max-height: 350px; }
    </style>
    """, unsafe_allow_html=True)

# 3. åˆå§‹åŒ– API å®¢æˆ·ç«¯
api_key_val = st.secrets.get("GEMINI_API_KEY", "")
@st.cache_resource
def get_client(key):
    return Client(api_key=key) if key else None

client = get_client(api_key_val)

# 4. åˆå§‹åŒ–çŠ¶æ€å˜é‡ (æŒä¹…åŒ–å¯¹è¯çš„å…³é”®)
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []  # æ ¼å¼: {"role": "...", "content": "..."}
if "scores" not in st.session_state:
    st.session_state.scores = {"Content": 0, "Organization": 0, "Language": 0}
if "last_report" not in st.session_state:
    st.session_state.last_report = ""

# 5. ä¾§è¾¹æ 
with st.sidebar:
    st.title("ğŸ” æˆå‘˜å‡†å…¥")
    access_code = st.text_input("è¯·è¾“å…¥é‚€è¯·ç è§£é”", type="password")
    if access_code != "DSE2026":
        st.warning("è¯·è¾“å…¥æ­£ç¡®é‚€è¯·ç ä»¥ä½¿ç”¨å¯¼å¸ˆåŠŸèƒ½ã€‚")
        st.stop()
    
    st.success("éªŒè¯æˆåŠŸï¼")
    st.divider()
    st.title("ğŸ“š DSE å·¥å…·ç®±")
    with st.expander("é«˜åˆ†è¿è¯åº“"):
        st.write("- Addition: Furthermore, Notably\n- Contrast: Paradoxically\n- Cause: Stemming from")

# 6. ä¸»ç•Œé¢
st.title("ğŸ¤– DSE AI è¶…çº§å¯¼å¸ˆ Pro")
st.caption("åŸºäº Google Gemini 3.0 Flash å¼•æ“çš„è€ƒå®˜çº§äº’åŠ¨å¹³å°")

col1, col2 = st.columns([1, 1], gap="large")

with col1:
    st.markdown("### ğŸ“¥ ç¬¬ä¸€æ­¥ï¼šæäº¤ä½œæ–‡")
    task_type = st.selectbox("é€‰æ‹©é¢˜å‹", ["Part A", "Part B", "Argumentative", "Letter to Editor"])
    target_lv = st.select_slider("ç›®æ ‡ç­‰çº§", options=["3", "4", "5", "5*", "5**"])
    user_text = st.text_area("åœ¨æ­¤ç²˜è´´ä½ çš„ä½œæ–‡...", height=300)
    
    if st.button("ğŸš€ ç”Ÿæˆæ·±åº¦æ‰¹æ”¹æŠ¥å‘Š"):
        if user_text:
            with st.spinner("æ­£åœ¨ä»¥è€ƒå®˜é€»è¾‘é˜…å·..."):
                prompt = f"""
                ä½ æ˜¯ä¸€ä½ç²¾é€šDSEè¯„åˆ†æ ‡å‡†çš„è€ƒå®˜ã€‚è¯·å¯¹è¿™ç¯‡{task_type}ä½œæ–‡ç»™Level {target_lv}ç›®æ ‡çš„åŒå­¦å†™ä¸€ä»½ç¹ä½“ä¸­æ–‡æŠ¥å‘Šã€‚
                è¦æ±‚ï¼š
                1. æŒ‡å‡º Content, Organization, Language çš„ä¼˜ç¼ºç‚¹ã€‚
                2. æä¾› Level 5** çº§åˆ«çš„ç¤ºèŒƒæ”¹å†™ã€‚
                3. æœ€åä¸€è¡Œå¿…é¡»ä¸¥æ ¼è¾“å‡ºï¼šSCORES: C:æ•°å­—, O:æ•°å­—, L:æ•°å­— (æ»¡åˆ†7)
                """
                response = client.models.generate_content(model="gemini-3-flash-preview", contents=[prompt, user_text])
                full_text = response.text
                
                # åˆ†æ•°è§£æ
                score_match = re.search(r"SCORES: C:(\d), O:(\d), L:(\d)", full_text)
                if score_match:
                    st.session_state.scores = {
                        "Content": int(score_match.group(1)),
                        "Organization": int(score_match.group(2)),
                        "Language": int(score_match.group(3))
                    }
                
                st.session_state.last_report = full_text.split("SCORES:")[0]
                # åˆå§‹åŒ–å¯¹è¯ï¼Œå¹¶æ³¨å…¥â€œè€ƒå®˜è®°å¿†â€
                st.session_state.chat_history = [
                    {"role": "ai", "content": "å ±å‘Šå·²ç”Ÿæˆï¼æˆ‘å·²æ ¹æ“š DSE æ¨™æº–å®Œæˆæ‰¹æ”¹ã€‚ä½ å¯ä»¥é‡å°å ±å‘Šå…§å®¹å‘æˆ‘æå•ã€‚"}
                ]
        else:
            st.warning("è«‹å…ˆè¼¸å…¥ä½œæ–‡å…§å®¹ã€‚")

    # é›·è¾¾å›¾ä¸æŠ¥å‘Šæ˜¾ç¤º
    if st.session_state.last_report:
        categories = list(st.session_state.scores.keys())
        values = list(st.session_state.scores.values())
        fig = go.Figure(data=go.Scatterpolar(r=values + [values[0]], theta=categories + [categories[0]], fill='toself', line_color='#fbbf24'))
        fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 7])), showlegend=False, height=300)
        st.plotly_chart(fig, use_container_width=True)
        st.markdown("---")
        st.markdown(st.session_state.last_report)

with col2:
    st.markdown("### ğŸ’¬ ç¬¬äºŒæ­¥ï¼š1-on-1 å¯¼å¸ˆè¿½é—®")
    
    # å®¹å™¨åŒ–å¯¹è¯æ¡†ï¼Œé˜²æ­¢æ»šåŠ¨
    chat_container = st.container(height=600)
    
    with chat_container:
        if not st.session_state.last_report:
            st.info("å®Œæˆå·¦ä¾§æ‰¹æ”¹åï¼Œå¯¼å¸ˆå°†åœ¨æ­¤ä¸ºä½ è§£ç­”ç–‘é—®ã€‚")
        else:
            # æ¸²æŸ“å†å²å¯¹è¯
            for msg in st.session_state.chat_history:
                with st.chat_message(msg["role"]):
                    st.write(msg["content"])
    
    # å¯¹è¯è¾“å…¥æ¡†
    if prompt_input := st.chat_input("é—®é—®å¯¼å¸ˆï¼šä¸ºä»€ä¹ˆè¿™é‡Œè¦è¿™æ ·æ”¹ï¼Ÿ"):
        # æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
        st.session_state.chat_history.append({"role": "user", "content": prompt_input})
        with chat_container:
            with st.chat_message("user"):
                st.write(prompt_input)
            
            with st.chat_message("ai"):
                with st.spinner("æ€è€ƒä¸­..."):
                    # æ„å»ºåŒ…å«ä¸Šä¸‹æ–‡çš„è¯·æ±‚
                    context_msg = f"""
                    ä½ æ˜¯ä¸€ä½DSEå°å¸«ã€‚
                    å­¸ç”ŸåŸæ–‡ï¼š{user_text}
                    ä½ çš„æ‰¹æ”¹å ±å‘Šï¼š{st.session_state.last_report}
                    å­¸ç”Ÿæå•ï¼š{prompt_input}
                    è«‹é‡å°æå•çµ¦äºˆå°ˆæ¥­ã€é¼“å‹µæ€§çš„æŒ‡å°ã€‚ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚
                    """
                    response = client.models.generate_content(model="gemini-3-flash-preview", contents=context_msg)
                    st.write(response.text)
                    st.session_state.chat_history.append({"role": "ai", "content": response.text})
